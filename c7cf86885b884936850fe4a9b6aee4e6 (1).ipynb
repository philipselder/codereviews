{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/arcgis/gis/__init__.py:597: UserWarning: You are logged on as ben10453@esri.com_DBSNE with an administrator role, proceed with caution.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml\n",
    "import xml.etree.ElementTree as et\n",
    "import math\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "import arcpy\n",
    "arcpy.GetInstallInfo()['Version']\n",
    "gis = GIS(\"home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Region variables and data variables for FAA API Query\n",
    "region = 'AEA'\n",
    "\n",
    "case = 'OE'\n",
    "#case = 'NRA'\n",
    "\n",
    "year = datetime.datetime.today().year\n",
    "years = [year - i for i in range(6)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_XML(xml_string, df_cols): \n",
    "    \"\"\"Parse the input XML string and store the result in a pandas \n",
    "    DataFrame with the given columns. \n",
    "    \"\"\"\n",
    "    \n",
    "    xroot = et.fromstring(xml_string)\n",
    "    rows = []\n",
    "    \n",
    "    for node in xroot: \n",
    "        res = []\n",
    "        res.append(node.attrib.get(df_cols[0]))\n",
    "        for el in df_cols[1:]: \n",
    "            if node is not None and node.find(el) is not None:\n",
    "                res.append(node.find(el).text)\n",
    "            else: \n",
    "                res.append(None)\n",
    "        rows.append({df_cols[i]: res[i] \n",
    "                     for i, _ in enumerate(df_cols)})\n",
    "    \n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)\n",
    "    out_df.drop('OECase', axis=1, inplace=True)\n",
    "    out_df['latitude'] = out_df['latitude'].astype('float64')\n",
    "    out_df['longitude'] = out_df['longitude'].astype('float64')\n",
    "    out_df['aglStructureHeight'] = out_df['aglStructureHeight'].astype('int')\n",
    "    out_df['dateEntered'] = pd.to_datetime(out_df['dateEntered'],format='%Y-%m-%d')\n",
    "    out_df['expirationDate'] = pd.to_datetime(out_df['expirationDate'],format='%Y-%m-%d')\n",
    "    out_df['dateCompleted'] = pd.to_datetime(out_df['dateCompleted'],format='%Y-%m-%d')\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of attribute header names matching exact XML schema\n",
    "\n",
    "headers=[\"OECase\",\"id\",\n",
    "\"asn\",\n",
    "\"asnSequence\",\n",
    "\"dateEntered\",\n",
    "\"expirationDate\",\n",
    "\"dateCompleted\",\n",
    "\"caseType\",\n",
    "\"nearestAirportName\",\n",
    "\"nearestState\",\n",
    "\"nearestCity\",\n",
    "\"siteElevationProposed\",\n",
    "\"aglStructureHeight\",\n",
    "\"statusCode\",\n",
    "\"year\",\n",
    "\"sponsor\",\n",
    "\"sponsorAddress1\",\n",
    "\"sponsorCity\",\n",
    "\"sponsorState\",\n",
    "\"sponsorPostalCode\",\n",
    "\"faaGeographyId\",\n",
    "\"distanceFromNearestAirport\",\n",
    "\"directionFromNearestAirport\",\n",
    "\"structureDescription\",\n",
    "\"structureType\",\n",
    "\"locatorId\",\n",
    "\"latitude\",\n",
    "\"longitude\",\n",
    "\"sponsorEmail\",\n",
    "\"sponsorCountry\",\n",
    "\"sponsorPhone\",\n",
    "\"receivedDate\",\n",
    "\"amslOverallHeightProposed\",\n",
    "\"latLongAccuracy\",\n",
    "\"EditFlag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the XML response from FAA API\n",
    "df_list = []\n",
    "for y in years:\n",
    "    url = f'https://oeaaa.faa.gov/oeaaa/services/caseList/{case}/{y}?region={region}'\n",
    "    get = requests.get(url)\n",
    "    content = get.content\n",
    "    xmlData = content.decode('utf-8')\n",
    "    out_df=parse_XML(xmlData, headers)\n",
    "    codes=['JFK','5I6','LGA','NY07','EWR','UNU','SWF','17V','TEB']\n",
    "    df=out_df[out_df.nearestAirportName.isin(codes)]\n",
    "    df_list.append(df)\n",
    "    print(y, \"has been appended\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obst_df=pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create spatial data frame\n",
    "\n",
    "sedf= pd.DataFrame.spatial.from_xy(obst_df, 'longitude', 'latitude')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this if no hosted feature service exists yet\n",
    "#lyr = sedf.spatial.to_featurelayer('FAA Obstacles')\n",
    "#lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get hosted feature layer and create a spatial data frame\n",
    "\n",
    "item = gis.content.get(\"4626b7b4c72d417997d0a4da0c0a7ba5\")\n",
    "flayer = item.layers[0]\n",
    "sdf = pd.DataFrame.spatial.from_layer(flayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query features\n",
    "\n",
    "feats = flayer.query()\n",
    "\n",
    "#Loop through and change Edit Flag\n",
    "\n",
    "feats_to_edit = []\n",
    "for feat in feats.features:\n",
    "    feat_edit = feat # nested dictionary\n",
    "\n",
    "\n",
    "    old_value = feat.attributes['EditFlag']\n",
    "    \n",
    "    new_value = \"0\"\n",
    "    \n",
    "    # update the nested dictionary\n",
    "    feat_edit.attributes['EditFlag'] = new_value\n",
    "\n",
    "    feats_to_edit.append(feat_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new features in 9 chunks\n"
     ]
    }
   ],
   "source": [
    "#Update layer so Edit Flag is ready for new/changed features\n",
    "\n",
    "max_feats = 500\n",
    "new_features = feats_to_edit\n",
    "output_flayer = flayer\n",
    "if len(new_features) > max_feats:\n",
    "    # update in chunks\n",
    "    chunks = math.ceil(len(new_features) / max_feats)\n",
    "    new_feat_chunks = np.array_split(new_features, chunks)\n",
    "    print(\"Adding new features in {} chunks\".format(chunks))\n",
    "    for x in new_feat_chunks:\n",
    "        output_flayer.edit_features(updates = x)\n",
    "else:\n",
    "    output_flayer.edit_features(updates = new_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge function to search on specific field value\n",
    "\n",
    "def clean_merge(df,value_field=None):\n",
    "\n",
    "    ## Make a copy of the input data\n",
    "    df_copy = df.copy(True)\n",
    "    if value_field is not None:\n",
    "        df_copy = df_copy.loc[df_copy[value_field+\"_old\"] != df_copy[value_field]]\n",
    "    cols = [c for c in df_copy.columns if c.endswith('_old')]\n",
    "    cols.append('_merge')\n",
    "    return df_copy.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify function that uses previous merge function to create an add, updates, and deletes df based on merge results.\n",
    "\n",
    "def identify_edits(exist_df,newdata_df,id_field,value_field=None):\n",
    "    \n",
    "    if exist_df.empty:\n",
    "        adds = newdata_df\n",
    "        upds = pd.DataFrame()\n",
    "    else:\n",
    "        mdf = pd.merge(left=exist_df,\n",
    "                       right=newdata_df,\n",
    "                       on=id_field,\n",
    "                       indicator=True,\n",
    "                       how=\"outer\",\n",
    "                       suffixes=['_old','']\n",
    "                      )\n",
    "        adds = clean_merge(mdf.loc[mdf['_merge'] == 'right_only'],value_field)\n",
    "        upds = clean_merge(mdf.loc[mdf['_merge'] == 'both'],value_field)\n",
    "        dels = clean_merge(mdf.loc[mdf['_merge'] == 'left_only'],value_field)\n",
    "    ## Fix OBJECTID field\n",
    "    adds = adds.drop(columns='OBJECTID')\n",
    "    adds['EditFlag'] = '1'\n",
    "    upds['OBJECTID'] = upds['OBJECTID'].astype(int)\n",
    "    upds['EditFlag'] = '1'\n",
    "    dels['OBJECTID'] = dels['OBJECTID'].astype(int)\n",
    "    return adds, upds, dels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run function\n",
    "\n",
    "adds,upds,dels = identify_edits(sdf,sedf,\"id\",value_field=\"statusCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add, Update, or Delete features\n",
    "if adds.empty:\n",
    "    pass\n",
    "else:\n",
    "    add_result = flayer.edit_features(adds = adds.spatial.to_featureset())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add, Update, or Delete features\n",
    "if upds.empty:\n",
    "    pass\n",
    "else:\n",
    "    update_result = flayer.edit_features(updates = upds.spatial.to_featureset())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add, Update, or Delete features\n",
    "if dels.empty:\n",
    "    pass\n",
    "else:\n",
    "    dels_list = dels[\"OBJECTID\"].tolist()\n",
    "    delete_result = flayer.edit_features(deletes = dels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "7.0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
